        <p class="heading2"><a name="Usage"></a>Usage Notes</p>
        <p class="body">As mentioned earlier, you can have <code>SYSCS_UTIL.BULK_IMPORT_HFILE</code> automatically compute the splits for your table; it does so by sampling the data in the table, generating a histogram, and then using that histogram to compute the import splits. <code>SYSCS_UTIL.BULK_IMPORT_HFILE</code> automatically computes the splits when the <code>skipSampling</code> parameter is set to <code>false</code>.</p>
        <p class="heading3">Computing Split Keys for HFile Import</p>
        <p class="noteIcon">If you are using <code>skipSampling=false</code> to allow automatic computation of splits, you can ignore the rest of this section, and skip to the <a href="#Examples">Examples</a> section below.</p>
        <p>If you're computing splits for your import (and setting the <code>skipSampling</code> parameter to <code>true</code>), you need to use these three Splice&#160;Machine system procedures together:</p>
        <ul>
            <li><code>SYSCS_UTIL.COMPUTE_SPLIT_KEY</code> generates a keys file</li>
            <li><code>SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX_AT_POINTS</code> sets up the splits in Splice&#160;Machine</li>
            <li><code>SYSCS_UTIL.BULK_IMPORT_HFILE</code>&#160;splits your input file into HFiles, imports your data, and then removes the HFiles</li>
        </ul>
        <p>Alternatively, you can use  <code><a href="sqlref_sysprocs_splittable.html">SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX</a></code> with <code>SYSCS_UTIL.BULK_IMPORT_HFILE</code>. The <code>SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX</code> system procedure combines the functionality of <code>SYSCS_UTIL.COMPUTE_SPLIT_KEY</code> and <code>SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX_AT_POINTS</code>.</p>
        <p>The process is as follows (and is shown in more detail in <em>Example 1</em> and <em>Example 2</em> below):</p>
        <div class="opsStepsList">
            <ol>
                <li>
                    <p>Create a directory on HDFS; for example:</p>
                    <div class="preWrapperWide"><pre class="ShellCommand">sudo -su hdfs hadoop fs -mkdir hdfs:///tmp/test_hfile_import</pre>
                    </div>
                    <p>Make sure that the directory you create has permissions set to allow Splice&#160;Machine to write your csv and Hfiles there.</p>
                </li>
                <li>
                    <p>Determine primary key values that can horizontally split the table into roughly equal sized partitions. </p>
                    <div class="noteNote">
                        <p>Note the value of your <code>hbase.hregion.max.filesize</code> setting; each partition should ideally be about 1/2 of that value, so that the region can grow after data is loaded. </p>
                        <p>The sizes must be less than the <code>hbase.hregion.max.filesize value</code>.</p>
                    </div>
                </li>
                <li>Store those keys in a CSV&#160;file.</li>
                <li> If you're using the combination of <code><a href="sqlref_sysprocs_computesplitkey.html">SYSCS_UTIL.COMPUTE_SPLIT_KEY</a></code> and <code><a href="sqlref_sysprocs_splittableatpoints.html">SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX_AT_POINTS</a></code>:<ol class="LowerAlphaPlainFont"><li>Pass that CSV&#160;file into the <code><a href="sqlref_sysprocs_computesplitkey.html">SYSCS_UTIL.COMPUTE_SPLIT_KEY</a></code>&#160;procedure to compute the split row keys.</li><li><p>Examine the computed (and encoded)&#160;row keys, which were written to a file named keys in a subdirectory of your <code>OutputDirectory</code>. </p><p>The name of the subdirectory is the conglomerate ID&#160;for the named table. You can find a table's conglomerate ID&#160;with the <code><a href="cmdlineref_showtables.html">SHOW&#160;TABLES</a></code>&#160;command.&#160;</p></li><li>Copy the encoded keys to your clipboard.</li><li>Call the <code><a href="sqlref_sysprocs_splittableatpoints.html">SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX_AT_POINTS</a></code>&#160;procedure, passing in the row key values from your clipboard. This splits your table inside the database.</li></ol><p>If you are using  the single procedure <code><a href="sqlref_sysprocs_splittable.html">SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX</a></code> instead:</p><ol class="LowerAlphaPlainFont"><li>Pass that CSV&#160;file into the <code><a href="sqlref_sysprocs_splittable.html">SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX</a></code>&#160;procedure to compute the split row keys and split your table inside the database.</li></ol></li>
                <li>Repeat steps 1, 2, and 3 to split the indexes on your table.</li>
                <li>Call the <code><a href="sqlref_sysprocs_importhfile.html">SYSCS_UTIL.BULK_IMPORT_HFILE</a></code>&#160;procedure to split the input data file into HFiles and import the HFiles into your Splice Machine database. The HFiles are deleted after being imported.</li>
            </ol>
        </div>
        <p class="heading2" id="Examples">Example 1</p>
        <p>This example details the steps used to import data in HFile format using the Splice Machine <code>SYSCS_UTIL.BULK_IMPORT_HFILE</code> system procedure with automatic splitting.</p>
        <p>Follow these steps :</p>
        <div class="opsStepsList">
            <ol class="boldFont">
                <li>
                    <p class="topLevel">Create a directory on HDFS for the import; for example:</p>
                    <div class="preWrapperWide"><pre class="ShellCommand">sudo -su hdfs hadoop fs -mkdir hdfs:///tmp/test_hfile_import</pre>
                    </div>
                    <p>Make sure that the directory you create has permissions set to allow Splice&#160;Machine to write your csv and Hfiles there.</p>
                </li>
                <li>
                    <p class="topLevel">Create table and index:</p>
                    <div class="preWrapperWide"><pre class="Example">CREATE TABLE TPCH.LINEITEM (
		 L_ORDERKEY BIGINT NOT NULL,
		 L_PARTKEY INTEGER NOT NULL,
		 L_SUPPKEY INTEGER NOT NULL,
		 L_LINENUMBER INTEGER NOT NULL,
		 L_QUANTITY DECIMAL(15,2),
		 L_EXTENDEDPRICE DECIMAL(15,2),
		 L_DISCOUNT DECIMAL(15,2),
		 L_TAX DECIMAL(15,2),
		 L_RETURNFLAG VARCHAR(1),
		 L_LINESTATUS VARCHAR(1),
		 L_SHIPDATE DATE,
		 L_COMMITDATE DATE,
		 L_RECEIPTDATE DATE,
		 L_SHIPINSTRUCT VARCHAR(25),
		 L_SHIPMODE VARCHAR(10),
		 L_COMMENT VARCHAR(44),
		 PRIMARY KEY(L_ORDERKEY,L_LINENUMBER)
		 );

CREATE&#160;INDEX&#160;L_SHIPDATE_IDX on TPCH.LINEITEM(
		 L_SHIPDATE,
		 L_PARTKEY,
		 L_EXTENDEDPRICE,
		 L_DISCOUNT
		 );</pre>
                    </div>
                </li>
                <li>
                    <p class="topLevel">Import the HFiles Into Your Database</p>
                    <p class="indentLevel1">Once you have split your table and indexes, call this procedure to generate and import the HFiles into your Splice Machine database:</p>
                    <div class="preWrapperWide"><pre class="Example">call SYSCS_UTIL.BULK_IMPORT_HFILE('TPCH', 'LINEITEM', null, '/TPCH/1/lineitem', '|', null, null, null, null, -1, '/BAD', true, null, 'hdfs:///tmp/test_hfile_import/', false);</pre>
                    </div>
                    <p class="indentLevel1">The generated HFiles are automatically deleted after being imported.</p>
                </li>
            </ol>
        </div>
        <p class="heading2">Example 2</>
        <p>The example in this section details the steps used to import data in HFile format using the Splice Machine <code>SYSCS_UTIL.COMPUTE_SPLIT_KEY</code>,  <code>SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX_AT_POINTS</code>, and <code>SYSCS_UTIL.BULK_IMPORT_HFILE</code> system procedures.</p>
        <p>Follow these steps :</p>
        <div class="opsStepsList">
            <ol class="boldFont">
                <li>
                    <p class="topLevel">Create a directory on HDFS for the import; for example:</p>
                    <div class="preWrapperWide"><pre class="ShellCommand">sudo -su hdfs hadoop fs -mkdir hdfs:///tmp/test_hfile_import</pre>
                    </div>
                    <p>Make sure that the directory you create has permissions set to allow Splice&#160;Machine to write your csv and Hfiles there.</p>
                </li>
                <li>
                    <p class="topLevel">Create table and index:</p>
                    <div class="preWrapperWide"><pre class="Example">CREATE TABLE TPCH.LINEITEM (
		 L_ORDERKEY BIGINT NOT NULL,
		 L_PARTKEY INTEGER NOT NULL,
		 L_SUPPKEY INTEGER NOT NULL,
		 L_LINENUMBER INTEGER NOT NULL,
		 L_QUANTITY DECIMAL(15,2),
		 L_EXTENDEDPRICE DECIMAL(15,2),
		 L_DISCOUNT DECIMAL(15,2),
		 L_TAX DECIMAL(15,2),
		 L_RETURNFLAG VARCHAR(1),
		 L_LINESTATUS VARCHAR(1),
		 L_SHIPDATE DATE,
		 L_COMMITDATE DATE,
		 L_RECEIPTDATE DATE,
		 L_SHIPINSTRUCT VARCHAR(25),
		 L_SHIPMODE VARCHAR(10),
		 L_COMMENT VARCHAR(44),
		 PRIMARY KEY(L_ORDERKEY,L_LINENUMBER)
		 );

CREATE&#160;INDEX&#160;L_SHIPDATE_IDX on TPCH.LINEITEM(
		 L_SHIPDATE,
		 L_PARTKEY,
		 L_EXTENDEDPRICE,
		 L_DISCOUNT
		 );</pre>
                    </div>
                </li>
                <li>
                    <p class="topLevel">Compute the split row keys for the table:</p>
                    <ol class="LowerAlphaPlainFont">
                        <li>
                            <p>Find primary key values that can horizontally split the table into roughly equal sized partitions.</p>
                            <p>For this example, we provide 3 keys in a file named <code>lineitemKey.csv</code>. Note that each of our three keys includes a second column that is <code>null</code>:</p>
                            <div class="preWrapperWide"><pre class="Example">1500000|<br />3000000|<br />4500000|</pre>
                            </div>
                        </li>
                        <li>
                            <p>Specify the column names in the csv file in the <code>columnList</code> parameter; in our example, the primary key columns are:</p>
                            <div class="preWrapperWide"><pre class="Example">'L_ORDERKEY,L_LINENUMBER'</pre>
                            </div>
                        </li>
                        <li>
                            <p>Invoke <code>SYSCS_UTIL.COMPUTE_SPLIT_KEY</code> to compute hbase split row keys and write them to a file:</p><pre class="Example">call SYSCS_UTIL.COMPUTE_SPLIT_KEY('TPCH', 'LINEITEM',null, 'L_ORDERKEY,L_LINENUMBER', 'hdfs:///tmp/test_hfile_import/lineitemKey.csv', '|', null, null, null, null, -1, '/BAD', true, null, 'hdfs:///tmp/test_hfile_import/');</pre>
                        </li>
                    </ol>
                </li>
                <li>
                    <p class="topLevel">Set up the table splits in your database:</p>
                    <ol class="LowerAlphaPlainFont">
                        <li>
                            <p>Use <code>SHOW&#160;TABLES</code>&#160;to discover the conglomerate ID&#160;for the <code>TPCH.LINEITEM</code>&#160;table, which for this example is <code>1536</code>. This means that the split keys file for this table is in the <code>hdfs:///tmp/test_hfile_import/1536</code> directory. You'll see values like these:</p>
                            <div class="preWrapperWide"><pre class="Example">\xE4\x16\xE3`<br />\xE4-\xC6\xC0<br />\xE4D\xAA</pre>
                            </div>
                        </li>
                        <li>
                            <p>Now use those values in a call to our system procedure to split the table inside the database:</p>
                            <div class="preWrapperWide"><pre class="Example">call SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX_AT_POINTS('TPCH','LINEITEM',null,'\xE4\x16\xE3`,\xE4-\xC6\xC0,\xE4D\xAA');</pre>
                            </div>
                        </li>
                    </ol>
                </li>
                <li>
                    <p class="topLevel">Compute the split keys for your index:</p>
                    <ol class="LowerAlphaPlainFont">
                        <li>Find index values that can horizontally split the table into roughly equal sized partitions.</li>
                        <li>
                            <p>For this example, we provide 2 index values in a file named <code>shipDateIndex.csv</code>. Note that each of our keys includes <code>null</code> column values:</p>
                            <div class="preWrapperWide"><pre class="Example">1994-01-01|||
1996-01-01|||</pre>
                            </div>
                        </li>
                        <li>
                            <p>Specify the column names in the csv file in the <code>columnList</code> parameter; in our example, the index columns are:</p>
                            <div class="preWrapperWide"><pre class="Example">'L_SHIPDATE,L_PARTKEY,L_EXTENDEDPRICE,L_DISCOUNT'</pre>
                            </div>
                        </li>
                        <li>
                            <p>Invoke <code>SYSCS_UTIL.COMPUTE_SPLIT_KEY</code> to compute hbase split row keys and write them to a file:</p><pre class="Example">call SYSCS_UTIL.COMPUTE_SPLIT_KEY('TPCH', 'LINEITEM', 'L_SHIPDATE_IDX', 'L_SHIPDATE,L_PARTKEY,L_EXTENDEDPRICE,L_DISCOUNT', 'hdfs:///tmp/test_hfile_import/shipDateIndex.csv', '|', null, null, null, null, -1, '/BAD', true, null, 'hdfs:///tmp/test_hfile_import/');
</pre>
                        </li>
                    </ol>
                </li>
                <li>
                    <p class="topLevel">Set up the indexes in your database:</p>
                    <ol class="LowerAlphaPlainFont">
                        <li>
                            <p>Copy the row key values from the output file:</p>
                            <div class="preWrapperWide"><pre class="Example">\xEC\xB0Y9\xBC\x00\x00\x00\x00\x00\x80
\xEC\xBF\x08\x9C\x14\x00\x00\x00\x00\x00\x80</pre>
                            </div>
                        </li>
                        <li>
                            <p>Now call our system procedure to split the index:</p>
                            <div class="preWrapperWide"><pre class="Example">call SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX_AT_POINTS('TPCH','LINEITEM','L_SHIPDATE_IDX','\xEC\xB0Y9\xBC\x00\x00\x00\x00\x00\x80,\xEC\xBF\x08\x9C\x14\x00\x00\x00\x00\x00\x80');
</pre>
                            </div>
                        </li>
                    </ol>
                </li>
                <li>
                    <p class="topLevel">Import the HFiles Into Your Database</p>
                    <p class="indentLevel1">Once you have split your table and indexes, call this procedure to generate and import the HFiles into your Splice Machine database:</p>
                    <div class="preWrapperWide"><pre class="Example">call SYSCS_UTIL.BULK_IMPORT_HFILE('TPCH', 'LINEITEM', null, '/TPCH/1/lineitem', '|', null, null, null, null, -1, '/BAD', true, null, 'hdfs:///tmp/test_hfile_import/', true);</pre>
                    </div>
                    <p class="indentLevel1">The generated HFiles are automatically deleted after being imported.</p>
                </li>
            </ol>
        </div>
        <p class="heading2">Example 3</p>
        <p>The example in this section details the steps used to import data in HFile format using the Splice Machine  <code>SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX</code>, and <code>SYSCS_UTIL.BULK_IMPORT_HFILE</code> system procedures.</p>
        <p>Follow these steps :</p>
        <div class="opsStepsList">
            <ol class="boldFont">
                <li>
                    <p class="topLevel">Create a directory on HDFS for the import; for example:</p>
                    <div class="preWrapperWide"><pre class="ShellCommand">sudo -su hdfs hadoop fs -mkdir hdfs:///tmp/test_hfile_import</pre>
                    </div>
                    <p>Make sure that the directory you create has permissions set to allow Splice&#160;Machine to write your csv and Hfiles there.</p>
                </li>
                <li>
                    <p class="topLevel">Create table and index:</p>
                    <div class="preWrapperWide"><pre class="Example">CREATE TABLE TPCH.LINEITEM (
		 L_ORDERKEY BIGINT NOT NULL,
		 L_PARTKEY INTEGER NOT NULL,
		 L_SUPPKEY INTEGER NOT NULL,
		 L_LINENUMBER INTEGER NOT NULL,
		 L_QUANTITY DECIMAL(15,2),
		 L_EXTENDEDPRICE DECIMAL(15,2),
		 L_DISCOUNT DECIMAL(15,2),
		 L_TAX DECIMAL(15,2),
		 L_RETURNFLAG VARCHAR(1),
		 L_LINESTATUS VARCHAR(1),
		 L_SHIPDATE DATE,
		 L_COMMITDATE DATE,
		 L_RECEIPTDATE DATE,
		 L_SHIPINSTRUCT VARCHAR(25),
		 L_SHIPMODE VARCHAR(10),
		 L_COMMENT VARCHAR(44),
		 PRIMARY KEY(L_ORDERKEY,L_LINENUMBER)
		 );

CREATE&#160;INDEX&#160;L_SHIPDATE_IDX on TPCH.LINEITEM(
		 L_SHIPDATE,
		 L_PARTKEY,
		 L_EXTENDEDPRICE,
		 L_DISCOUNT
		 );</pre>
                    </div>
                </li>
                <li>
                    <p class="topLevel">Compute the split row keys for your table and set up the split in your database:</p>
                    <ol class="LowerAlphaPlainFont">
                        <li>
                            <p>Find primary key values that can horizontally split the table into roughly equal sized partitions.</p>
                            <p>For this example, we provide 3 keys in a file named <code>lineitemKey.csv</code>. Note that each of our three keys includes a second column that is <code>null</code>:</p>
                            <div class="preWrapperWide"><pre class="Example">1500000|<br />3000000|<br />4500000|</pre>
                            </div>
                        </li>
                        <li>
                            <p>Specify the column names in the csv file in the <code>columnList</code> parameter; in our example, the primary key columns are:</p>
                            <div class="preWrapperWide"><pre class="Example">'L_ORDERKEY,L_LINENUMBER'</pre>
                            </div>
                        </li>
                        <li>
                            <p>Invoke <code>SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX</code> to compute hbase split row keys and set up the splits</p><pre class="Example">call SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX('TPCH', 'LINEITEM',null, 'L_ORDERKEY,L_LINENUMBER', 'hdfs:///tmp/test_hfile_import/lineitemKey.csv', '|', null, null, null, null, -1, '/BAD', true, null);</pre>
                        </li>
                    </ol>
                </li>
                <li>
                    <p class="topLevel">Compute the split keys for your index:</p>
                    <ol class="LowerAlphaPlainFont">
                        <li>Find index values that can horizontally split the table into roughly equal sized partitions.</li>
                        <li>
                            <p>For this example, we provide 2 index values in a file named <code>shipDateIndex.csv</code>. Note that each of our keys includes <code>null</code> column values:</p>
                            <div class="preWrapperWide"><pre class="Example">1994-01-01|||
1996-01-01|||</pre>
                            </div>
                        </li>
                        <li>
                            <p>Specify the column names in the csv file in the <code>columnList</code> parameter; in our example, the index columns are:</p>
                            <div class="preWrapperWide"><pre class="Example">'L_SHIPDATE,L_PARTKEY,L_EXTENDEDPRICE,L_DISCOUNT'</pre>
                            </div>
                        </li>
                        <li>
                            <p>Invoke <code>SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX</code> to compute hbase split row keys and set up the index splits</p><pre class="Example">call SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX('TPCH', 'LINEITEM', 'L_SHIPDATE_IDX', 'L_SHIPDATE,L_PARTKEY,L_EXTENDEDPRICE,L_DISCOUNT', 'hdfs:///tmp/test_hfile_import/shipDateIndex.csv', '|', null, null, null, null, -1, '/BAD', true, null);
</pre>
                        </li>
                    </ol>
                </li>
                <li>
                    <p class="topLevel">Import the HFiles Into Your Database</p>
                    <p class="indentLevel1">Once you have split your table and indexes, call this procedure to generate and import the HFiles into your Splice Machine database:</p>
                    <div class="preWrapperWide"><pre class="Example">call SYSCS_UTIL.BULK_IMPORT_HFILE('TPCH', 'LINEITEM', null, '/TPCH/1/lineitem', '|', null, null, null, null, -1, '/BAD', true, null, 'hdfs:///tmp/test_hfile_import/', true);</pre>
                    </div>
                    <p class="indentLevel1">The generated HFiles are automatically deleted after being imported.</p>
                </li>
            </ol>
        </div>
