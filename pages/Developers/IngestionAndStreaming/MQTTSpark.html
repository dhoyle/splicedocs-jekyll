---
title: MQTT Spark Streaming with Splice Machine
summary: A tutorial showing you how to put messages on an MQTT queue, how to consume those messages using Spark Streaming, and how to save those messages to Splice Machine using a VTI.&#xD;&#xA;
keywords: 
toc: false
product: all
sidebar: developers_sidebar
permalink: developers_ingestion_mqttSpark.html
folder: Developers/IngestionAndStreaming
---
	<section>
		<div class="TopicContent">
            <h1><a name="kanchor453"></a>Streaming MQTT&#160;Spark Data</h1>
            <p>This topic walks you through using MQTT Spark streaming with Splice&#160;Machine. MQTT&#160;is a lightweight, publish-subscribe messaging protocol designed for connecting remotely when a small footprint is required. MQTT&#160;is frequently used for data collection with the Internet of Things (IoT).</p>
            <p>The example code in this tutorial uses <a href="https://mosquitto.org/" target="_blank">Mosquitto</a>, which is an open source message broker that implements the MQTT. This tutorial uses a cluster managed by MapR; if you're using different platform management software, you'll need to make a few adjustments in how the code is deployed on your cluster.</p>
            <div class="noteNote">All of the code used in this tutorial is available in our <a href="https://github.com/splicemachine/splice-community-sample-code" target="_blank">GitHub community repository</a>. <br /></div>
            <div data-mc-conditions="Default.NotPDF">
                <p>You can complete this tutorial by <a href="#Watch">watching a short video</a> or by <a href="#Written">following the written directions</a> below.</p>
                <h2><a name="Watch"></a>Watch the Video</h2>
                <p>The following video shows you how to:</p>
                <ul>
                    <li value="1"> put messages on an MQTT&#160;queue</li>
                    <li value="2">consume those messages using Spark streaming</li>
                    <li value="3">save those messages to Splice Machine with a virtual table (VTI)</li>
                </ul>
                <div class="centered">
                    <p><iframe class="youtube-player_0" src="https://www.youtube.com/embed/Nt2J2khM0Xw?" frameborder="0" allowfullscreen="1" width="560px" height="315px"></iframe>
                    </p>
                </div>
            </div>
            <h2><a name="Written"></a>Written Walk Through</h2>
            <p>This section walks you through the same sequence of steps as the video, in these sections:</p>
            <ul>
                <li value="1"> <a href="#Deployin">Deploying the Tutorial Code</a> walks you through downloading and deploying the sample code.</li>
                <li value="2"><a href="#About">About the Sample Code</a> describes the high-level methods in each class.</li>
                <li value="3"><a href="#About2">About the Sample Code Scripts</a> describes the scripts used to deploy and execute the sample code.</li>
            </ul>
            <h3><a name="Deployin"></a>Deploying the Tutorial Code</h3>
            <p>Follow these steps to deploy the tutorial code:</p>
            <div class="opsStepsList">
                <ol class="boldFont">
                    <li value="1">
                        <p class="topLevel">Download the code from  our <a href="https://github.com/splicemachine/splice-community-sample-code/tree/master/tutorial-mqtt-spark-streaming" target="_blank">GitHub community repository.</a></p>
                        <p class="indentLevel1">Pull the code from our git repository:</p>
                        <div class="preWrapperWide"><pre class="Plain"><a href="https://github.com/splicemachine/splice-community-sample-code/tree/master/tutorial-storm" target="_blank">https://github.com/splicemachine/splice-community-sample-code/tree/master/tutorial-mqtt-spark-streaming</a></pre>
                        </div>
                    </li>
                    <li value="2">
                        <p class="topLevel">Compile and package the code:</p>
                        <div class="preWrapperWide"><pre class="ShellCommand">mvn clean compile package<br /></pre>
                        </div>
                    </li>
                    <li value="3">
                        <p class="topLevel">Copy three JAR&#160;files to each server:</p>
                        <p class="indentLevel1">Copy these three files:</p>
                        <div class="preWrapperWide"><pre class="Plain">./target/splice-tutorial-mqtt-2.0.jar<br />spark-streaming-mqtt_2.10-1.6.1.jar<br />org.eclipse.paho.client.mqttv3-1.1.0.jar<br /></pre>
                        </div>
                        <p class="indentLevel1">to this directory on each server:</p>
                        <div class="preWrapperWide"><pre class="Plain"> /opt/splice/default/lib</pre>
                        </div>
                    </li>
                    <li value="4">
                        <p class="topLevel">Restart Hbase</p>
                    </li>
                    <li value="5">
                        <p class="topLevel">Create the target table in splice machine:</p>
                        <p class="indentLevel1">Run this script to create the table:</p>
                        <div class="preWrapperWide"><pre class="Plain"> create-tables.sql</pre>
                        </div>
                    </li>
                    <li value="6">
                        <p class="topLevel">Start Mosquitto:</p>
                        <div class="preWrapperWide"><pre class="ShellCommand">sudo su /usr/sbin/mosquitto -d -c /etc/mosquitto/mosquitto.conf &gt; /var/log/mosquitto.log 2&gt;&amp;1</pre>
                        </div>
                    </li>
                    <li value="7">
                        <p class="topLevel">Start the Spark streaming script:</p>
                        <div class="preWrapperWide"><pre class="ShellCommand">sudo -su mapr ./run-mqtt-spark-streaming.sh tcp://srv61:1883 /testing 10</pre>
                        </div>
                        <p class="indentLevel1">The first parameter (<span class="CodeFont">tcp://srv61:1883</span>)&#160;is the MQTT broker, the second (<span class="CodeFont">/testing</span>) is the topic name, and the third (<span class="CodeFont">10</span>)&#160;is the number of seconds each stream should run.</p>
                    </li>
                    <li value="8">
                        <p class="topLevel">Start putting messages on the queue:</p>
                        <p class="indentLevel1">Here's a java program that is set up to put messages on the queue:</p>
                        <div class="preWrapperWide"><pre class="ShellCommand">java -cp /opt/splice/default/lib/splice-tutorial-mqtt-2.0-SNAPSHOT.jar:/opt/splice/default/lib/org.eclipse.paho.client.mqttv3-1.1.0.jar com.splicemachine.tutorials.sparkstreaming.mqtt.MQTTPublisher tcp://localhost:1883 /testing 1000 R1</pre>
                        </div>
                        <p class="indentLevel1">The first parameter (<span class="CodeFont">tcp://localhost:1883</span>)&#160;is the MQTT broker, the second (<span class="CodeFont">/testing</span>) is the topic name, the third (<span class="CodeFont">1000</span>)&#160;is the number of iterations to execute, and the fourth parameter (<span class="CodeFont">R1</span>)&#160;is a prefix for this run.</p>
                        <div class="noteNote">The source code for this utility program is in a different GitHub project than the rest of this code. You'll find it in the <span class="CodeFont"><a href="https://github.com/splicemachine/splice-community-sample-code/tree/master/tutorial-kafka-producer" target="_blank">tutorial-kafka-producer</a></span> Github project. </div>
                    </li>
                </ol>
            </div>
            <h3><a name="About"></a>About the Sample Code</h3>
            <p>This section describes the main class methods used in this MQTT&#160;example code; here's a summary of the classes:</p>
            <table>
                <col />
                <col />
                <thead>
                    <tr>
                        <th>Java Class</th>
                        <th>Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td class="CodeFont"><a href="#MQTTPubl">MQTTPublisher</a>
                        </td>
                        <td>Puts csv messages on an MQTT&#160;queue.</td>
                    </tr>
                    <tr>
                        <td class="CodeFont"><a href="#SparkStr">SparkStreamingMQTT</a>
                        </td>
                        <td>The Spark streaming job that reads messages from the MQTT&#160;queue.</td>
                    </tr>
                    <tr>
                        <td class="CodeFont"><a href="#SaveRDD">SaveRDD</a>
                        </td>
                        <td>Inserts the data into Splice&#160;Machine using the <span class="CodeFont">RFIDMessageVTI</span> class.</td>
                    </tr>
                    <tr>
                        <td class="CodeFont"><a href="#RFIDMess2">RFIDMessageVTI</a>
                        </td>
                        <td>A virtual table interface for parsing an <span class="CodeFont">RFIDMessage</span>.</td>
                    </tr>
                    <tr>
                        <td class="CodeFont"><a href="#RFIDMess">RFIDMessage</a>
                        </td>
                        <td>Java object (a POJO)&#160;for converting from a csv string to an object to a database entry.</td>
                    </tr>
                </tbody>
            </table>
            <h4><a name="MQTTPubl"></a>MQTTPublisher</h4>
            <p>This class puts CSV messages on an MQTT queue. The function of most interest in MQTTPublisher.java is <span class="CodeFont">DoDemo</span>, which controls our sample program:</p>
            <div class="preWrapperWide"><pre class="Example">public void doDemo() {
   try {
		long startTime = System.currentTimeMillis();
		client = new MqttClient(broker, clientId);
		client.connect();
		MqttMessage message = new MqttMessage();
		for (int i=0; i‹numMessages; i++) {
			// Build a csv string
			message.setPayload( prefix + "Asset" + i ", Location" + i + "," + new Timestamp((new Date()).getTime())).getBytes());
			client.publish(topicName, message);
			if (i % 1000 == 0) {
				System.out.println("records:" + i + " duration=" + (System.currentTimeMillis() - startTime));
				startTime = System.currentTimeMillis();
			}
		client.disconnect();
	} catch (MqttException e) {
		e.printStackTrace();
	}
}</pre>
            </div>
            <p><span class="CodeFont">DoDemo</span> does a little initialization, then starts putting messages out on the queue. Our sample program is set up to loop until it creates <span class="CodeFont">numMessages</span> messages; after every 1000 messages, it displays a status message that helps us determine how much time is going to put messages on the queue, and how much to take them off the queue.</p>
            <p><span class="CodeFont">DoDemo</span> builds a csv record (line) for each message, setting an asset&#160;ID, a location ID, and a timestamp in the <span class="CodeFont">payload</span> of the message. It them publishes that message to the topic <span class="CodeFont">topicName</span>. </p>
            <h4><a name="SparkStr"></a>SparkStreamingMQTT</h4>
            <p>Once the messages are on the queue, our <span class="CodeFont">SparkStreamingMQTT</span> class object reads them from the queue and inserts them into our database. The main method in this class is <span class="CodeFont">processMQTT</span>:</p>
            <div class="preWrapperWide"><pre class="Example">public void processMQTT(final String broker, final String topic, final int numSeconds) {

        LOG.info("************ SparkStreamingMQTTOutside.processMQTT start");

        // Create the spark application and set the name to MQTT
        SparkConf sparkConf = new SparkConf().setAppName("MQTT");

        // Create the spark streaming context with a 'numSeconds' second batch size
        jssc = new JavaStreamingContext(sparkConf, Durations.seconds(numSeconds));
        jssc.checkpoint(checkpointDirectory);

        LOG.info("************ SparkStreamingMQTTOutside.processMQTT about to read the MQTTUtils.createStream");
        //2. MQTTUtils to collect MQTT messages
        JavaReceiverInputDStream‹String&gt; messages = MQTTUtils.createStream(jssc, broker, topic);

        LOG.info("************ SparkStreamingMQTTOutside.processMQTT about to do foreachRDD");
        //process the messages on the queue and save them to the database
        messages.foreachRDD(new SaveRDD());

        LOG.info("************ SparkStreamingMQTTOutside.processMQTT prior to context.strt");
        // Start the context
        jssc.start();
        jssc.awaitTermination();
    }</pre>
            </div>
            <p class="spaceAbove">The <span class="CodeFont">processMQTT</span>&#160;method takes three parameters:</p>
            <div class="paramList">
                <p class="paramName">broker</p>
                <p class="paramDefnFirst">The URL&#160;of the MQTT&#160;broker.</p>
                <p class="paramName">topic</p>
                <p class="paramDefnFirst">The MQTT&#160;topic name.</p>
                <p class="paramName">numSeconds</p>
                <p class="paramDefnFirst">The number of seconds at which streaming data will be divided into batches.</p>
            </div>
            <p class="spaceAbove">The <span class="CodeFont">processMQTT</span>&#160;method processes the messages on the queue and saves them by calling the <span class="CodeFont">SaveMDD</span> class.</p>
            <h4><a name="SaveRDD"></a>SaveRDD</h4>
            <p>The <span class="CodeFont">SaveRDD</span>&#160;class is an example of a Spark streaming function that uses our virtual table interface (VTI) to insert data into your Splice Machine database. This function checks for messages in the stream, and if there any, it creates a connection your database and uses a prepared statement to insert the messages into the database.</p>
            <div class="preWrapperWide"><pre class="Example">/**
 * This is an example of spark streaming function that
 * inserts data into Splice Machine using a VTI.
 *
 * @author Erin Driggers
 */

public class SaveRDD implements Function‹JavaRDD‹String&gt;, Void&gt;, Externalizable {

    private static final Logger LOG = Logger.getLogger(SaveRDD.class);

    @Override
    public Void call(JavaRDD‹String&gt; rddRFIDMessages) throws Exception {
        LOG.debug("About to read results:");
        if (rddRFIDMessages != null '&amp; rddRFIDMessages.count() &gt; 0) {
            LOG.debug("Data to process:");
            //Convert to list 
            List‹String&gt; rfidMessages = rddRFIDMessages.collect();
            int numRcds = rfidMessages.size();

            if (numRcds &gt; 0) {
                try {
                    Connection con = DriverManager.getConnection("jdbc:splice://localhost:1527/splicedb;user=splice;password=admin");

                    //Syntax for using a class instance in a VTI, this could also be a table function
                    String vtiStatement = "INSERT INTO IOT.RFID "
                            + "select s.* from new com.splicemachine.tutorials.sparkstreaming.mqtt.RFIDMessageVTI(?) s ("
                            + RFIDMessage.getTableDefinition() + ")";
                    PreparedStatement ps = con.prepareStatement(vtiStatement);
                    ps.setObject(1, rfidMessages);
                    ps.execute();
                } catch (Exception e) {
                    //It is important to catch the exceptions as log messages because it is difficult
                    //to trace what is happening otherwise
                    LOG.error("Exception saving MQTT records to the database" + e.getMessage(), e);
                } finally {
                    LOG.info("Complete insert into IOT.RFID");
                }
            }
        }
        return null;
    }
</pre>
            </div>
            <p class="spaceAbove">The heart of this function is the statement that creates the prepared statement, using a VTI&#160;class instance:</p>
            <div class="preWrapperWide"><pre class="Plain">String vtiStatement = "INSERT INTO IOT.RFID " <br />&#160;&#160;&#160;&#160;+ "select s.* from new <br />&#160;&#160;&#160;&#160;com.splicemachine.tutorials.sparkstreaming.mqtt.RFIDMessageVTI(?) s ("
&#160;&#160;&#160;&#160;+ RFIDMessage.getTableDefinition() + ")";
PreparedStatement ps = con.prepareStatement(vtiStatement);</pre>
            </div>
            <p>Note that the statement references both our <span class="CodeFont">RFIDMessage</span> and <span class="CodeFont">RFIDMessageVTI</span>&#160;classes, which are described below.</p>
            <h4><a name="RFIDMess2"></a>RFIDMessageVTI</h4>
            <p>The <span class="CodeFont">RFIDMessageVTI</span>&#160;class implements an example of a virtual table interface that reads in a list of strings that are in CSV&#160;format, converts that into an <span class="CodeFont">RFIDMessage</span> object, and returns the resultant list in a format that is compatible with Splice&#160;Machine.</p>
            <p>This class features an override of the <span class="CodeFont">getDataSet</span> method, which loops through each CSV&#160;record from the input stream and converts it into an <span class="CodeFont">RFIDMessage</span> object that is added onto a list of message items:</p>
            <div class="preWrapperWide"><pre class="Example">    @Override
    public DataSet‹LocatedRow&gt; getDataSet(SpliceOperation op, DataSetProcessor dsp, ExecRow execRow) throws StandardException {
        operationContext = dsp.createOperationContext(op);

        //Create an arraylist to store the key / value pairs
        ArrayList‹LocatedRow&gt; items = new ArrayList‹LocatedRow&gt;();

        try {

            int numRcds = this.records == null ? 0 : this.records.size();

            if (numRcds &gt; 0) {

                LOG.info("Records to process:" + numRcds);
                //Loop through each record convert to a SensorObject
                //and then set the values
                for (String csvString : records) {
                    CsvBeanReader beanReader = new CsvBeanReader(new StringReader(csvString), CsvPreference.STANDARD_PREFERENCE);
                    RFIDMessage msg = beanReader.read(RFIDMessage.class, header, processors);
                    items.add(new LocatedRow(msg.getRow()));
                }
            }
        } catch (Exception e) {
            LOG.error("Exception processing RFIDMessageVTI", e);
        } finally {
            operationContext.popScope();
        }
        return new ControlDataSet‹&gt;(items);
    }
</pre>
            </div>
            <div class="noteIcon">For more information about using our virtual table interface, see <a href="developers_fundamentals_vti.html">Using the Splice Machine Virtual Table Interface.</a></div>
            <h4><a name="RFIDMess"></a>RFIDMessage</h4>
            <p>The <span class="CodeFont">RFIDMessage</span> class creates a simple Java object (a POJO)&#160;that represents an RFID&#160;message; we use this to convert an incoming CSV-formatted message into an object. This class includes getters and setters for each of the object properties, plus the <span class="CodeFont">getTableDefinition</span> and <span class="CodeFont">getRow</span> methods:</p>
            <div class="preWrapperWide"><pre class="Example">    /**
     * Used by the VTI to build a Splice Machine compatible resultset
     *
     * @return
     * @throws SQLException
     * @throws StandardException
     */
    public ValueRow getRow() throws SQLException, StandardException {
        ValueRow valueRow = new ValueRow(5);
        valueRow.setColumn(1, new SQLVarchar(this.getAssetNumber()));
        valueRow.setColumn(2, new SQLVarchar(this.getAssetDescription()));
        valueRow.setColumn(3, new SQLTimestamp(this.getRecordedTime()));
        valueRow.setColumn(4, new SQLVarchar(this.getAssetType()));
        valueRow.setColumn(5, new SQLVarchar(this.getAssetLocation()));
        return valueRow;
    }

    /**
     * Table definition to use when using a VTI that is an instance of a class
     *
     * @return
     */
    public static String getTableDefinition() {
        return "ASSET_NUMBER varchar(50), "
        + "ASSET_DESCRIPTION varchar(100), "
        + "RECORDED_TIME TIMESTAMP, "
        + "ASSET_TYPE VARCHAR(50), "
        + "ASSET_LOCATION VARCHAR(50) ";
    }</pre>
            </div>
            <p>The <span class="CodeFont">getTableDefinition</span> method is a string description of the table into which you're inserting records; this pretty much replicates the specification you would use in an SQL&#160;<span class="CodeFont">CREATE_TABLE</span>&#160;statement.</p>
            <p>The <span class="CodeFont">getRow</span> method creates a data row with the appropriate number of columns, uses property getters to set the value of each column, and returns the row as a <span class="CodeFont">resultset</span> that is compatible with Splice&#160;Machine.</p>
            <h3><a name="About2"></a>About the Sample Code Scripts</h3>
            <p>These are also two scripts that we use with this tutorial:</p>
            <table>
                <col />
                <col />
                <thead>
                    <tr>
                        <th>Class</th>
                        <th>Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td class="CodeFont">/ddl/create-tables.sql</td>
                        <td>A simple SQL&#160;script that you can use to have Splice&#160;Machine create the table into which RFID&#160;messages are stored.</td>
                    </tr>
                    <tr>
                        <td class="CodeFont">/scripts/run-mqtt-spark-streaming.sh</td>
                        <td>Starts the Spark streaming job.</td>
                    </tr>
                </tbody>
            </table>
            <p style="font-size: 6pt;margin-top: 0;margin-bottom: 0;">&#160;</p>
        </div>
	</section>
