---
title: Introduction to the Splice Machine Database Console
summary: Describes the Splice Machine Database Console, which allows you to monitor (and kill) queries on your cluster in real time.
keywords: console, guide, ui, dbaas, paas, db
toc: false
product: all
sidebar:  dbconsole_sidebar
permalink: dbconsole_intro.html
folder: DBConsole
---
{% include splicevars.html %}
	<section>
		<div class="TopicContent" data-swiftype-index="true">
            <h1>Splice Machine Database Console Guide</h1>
            <p>This topic introduces the  <span class="ItalicFont">Splice Machine Database Console</span>, a browser-based tool that you can use to monitor database queries on your cluster in real time. The Console UI&#160;allows you to see the Spark queries that are currently running in Splice Machine on your cluster, and to then drill down into each job to see the current progress of the queries, and to identify any potential bottlenecks. If you see something amiss, you can also terminate a query.</p>
            <div class="noteIcon">The <span class="ItalicFont">Splice Machine Database Console</span> leverages the Spark cluster manager <span class="ItalicFont">Web UI</span>, which is described here:&#160;<a href="http://spark.apache.org/docs/latest/monitoring.html"  target="_blank">http://spark.apache.org/docs/latest/monitoring.html</a>.</div>
            <p>This section is organized into the following topics:</p>
            <ul>
                <li>The next section, <a href="#About">About the Splice Machine Database Console</a>, tells you about the Database Console, including how to access it in your browser.</li>
                <li>The <a href="dbconsole_features.html">Features of the Splice Machine Database Console</a> topic describes how to use major features of the console interface.</li>
                <li>The <a href="dbconsole_queries.html">Managing Queries with the Console</a> topic shows you how to review and monitor the progress of your Spark jobs.</li>
            </ul>
            <h2 id="About">About the Splice Machine Database Console</h2>
            <p>The  <span class="ItalicFont">Splice Machine Spark Database Console</span> is a browser-based tool that you can use to watch your active Spark queries execute and to review the execution of completed queries. You can use the console to:</p>
            <ul>
                <li>View any completed jobs</li>
                <li>Monitor active jobs as they execute</li>
                <li>View a timeline chart of the events in a job and its stages</li>
                <li>View a Directed Acyclic Graph (DAG)&#160;visualization of a job's stages and the tasks within each stage</li>
                <li>Monitor persisted and cached storage in realtime</li>
            </ul>
            <p>How you access the Splice&#160;Machine Database Console depends on which Splice Machine product you're using:</p>
			<table>
				<col />
				<col />
				<thead>
					<th>Product</th>
					<th>DB Console Access</th>
				</thead>
				<tbody>
					<tr>
						<td>Database-as-Service</td>
						<ul>
							<li>To monitor the Splice Machine jobs running on your cluster, click the <span class="ConsoleLink">DB Console</span> button at the top right of your Management screen or click the DB Console link in the cluster created email that you received from Splice Machine.</li>
							<li>To monitor any non-Splice Machine Spark jobs that are running on your cluster, you need to use a different Spark console, which you can access by clicking the <span class="ConsoleLink">External Spark Console</span> link that is displayed in the bottom left corner of your cluster's dashboard page.</td>
					</tr>
					<tr>
						<td>On-Premise Database</td>
						<td><div class="preWrapper"><pre class="AppCommand">{{splvar_location_SpliceMgmtConsoleUrl}}</pre></div></td>
            		</tr>
				</tbody>
			</table>
            <div class="noteIcon">The Database Console URL&#160;will only be active after you've run at least one query on our Spark engine; prior to using the Spark engine, your browser will report an error such as <span class="ItalicFont">Connection Refused</span>.</div>
            <p>Here are some of the terms you'll encounter while using the Database Console:</p>
            <table summary="Spark Database Console terminology">
                <col />
                <col />
                <thead>
                    <tr>
                        <th>Term</th>
                        <th>Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td class="ItalicFont">Accumulators</td>
                        <td>Accumulators are variables programmers can declare in Spark applications that can be efficiently supported in parallel operations, and are typically used to implement counters and sums. </td>
                    </tr>
                    <tr>
                        <td class="ItalicFont">Additional Metrics</td>
                        <td>You can indicate that you want to display additional metrics for a stage or job by clicking the <span class="AppCommand">Show Additional Metrics</span> arrow and then selecting which metrics you want shown.</td>
                    </tr>
                    <tr>
                        <td class="ItalicFont">DAG&#160;Visualization</td>
                        <td>A visual depiction of the execution Directed Acyclic Graph (DAG)&#160;for a job or job stage, which shows the details and flow of data. You can click the <span class="AppCommand">DAG&#160;Visualization</span> arrow to switch to this view.</td>
                    </tr>
                    <tr>
                        <td class="ItalicFont">Enable Zooming</td>
                        <td>For <span class="ItalicFont">event timeline</span> views, you can enable zooming to expand the view detail for a portion of the timeline. You can click the <span class="AppCommand">Event Timeline</span> arrow to switch to this view.</td>
                    </tr>
                    <tr>
                        <td class="ItalicFont">Event Timeline</td>
                        <td>A view that graphically displays the sequence of all <span class="ItalicFont">jobs</span>, a specific job, or a <span class="ItalicFont">stage</span> within a job. </td>
                    </tr>
                    <tr>
                        <td class="ItalicFont">Executor</td>
                        <td>A process that runs <span class="ItalicFont">tasks</span> on a cluster node.</td>
                    </tr>
                    <tr>
                        <td class="ItalicFont">GC Time</td>
                        <td>The amount of time spent performing garbage collection in a stage.</td>
                    </tr>
                    <tr>
                        <td class="ItalicFont">Job</td>
                        <td>
                            <p class="noSpaceAbove">The basic unit of execution in the Spark engine, consisting of a set of stages. With some exceptions, each query submitted to the Spark engine is a single job.</p>
                            <p>Each job is assigned a unique Job Id and is part of a unique Job Group.</p>
                        </td>
                    </tr>
                    <tr>
                        <td class="ItalicFont">Locality Level</td>
                        <td>To minimize data transfers, Spark tries to execute as close to the data as possible. The <span class="ItalicFont">Locality Level</span> value indicates whether a task was able to run on the local node.</td>
                    </tr>
                    <tr>
                        <td class="ItalicFont">Scheduling Mode</td>
                        <td>
                            <p class="noSpaceAbove">The scheduling mode used for a job.</p>
                            <p>In FIFO&#160;scheduling, the first job gets priority on all available resources while its stages have tasks to launch. Then the second job gets priority, and so on.</p>
                            <p>In FAIR&#160;scheduling, Spark assigns tasks between jobs in a round robin manner, meaning that all jobs get a roughly equal share of the available cluster resources. Which means that short jobs can gain fair access to resources immediately without having to wait for longer jobs to complete.</p>
                        </td>
                    </tr>
                    <tr>
                        <td class="ItalicFont">Scheduling Pool</td>
                        <td>The FAIR&#160;schedule groups jobs into pools, each of which can have a different priority weighting value, which allows you to submit jobs with higher or lower priorities.</td>
                    </tr>
                    <tr>
                        <td class="ItalicFont">ScrollInsensitive row</td>
                        <td>A&#160;row in a result set that is scrollable, and is not sensitive to changes committed by other transactions or by other statements in the same transaction.</td>
                    </tr>
                    <tr>
                        <td class="ItalicFont">Shuffling</td>
                        <td>
                            <p class="noSpaceAbove">Shuffling is the reallocation of data between multiple stages in a Spark job.</p>
                            <p><span class="ItalicFont">Shuffle Write</span> is amount of data that is serialized and written at the end of a stage for transmission to the next stage. <span class="ItalicFont">Shuffle Read</span> is the amount of serialized data that is read at the beginning of a stage.</p>
                        </td>
                    </tr>
                    <tr>
                        <td class="ItalicFont">Stage</td>
                        <td>
                            <p class="noSpaceAbove">The Splice Machine Spark scheduler splits the execution of a <span class="ItalicFont">job</span> into stages, based on the RDD&#160;transformations required to complete the job.</p>
                            <p>Each stage contains a group of tasks that perform a computation in parallel. </p>
                        </td>
                    </tr>
                    <tr>
                        <td class="ItalicFont">Task</td>
                        <td>A computational command sent from the application driver to an <span class="ItalicFont">executor</span> as part of a <span class="ItalicFont">stage</span>.</td>
                    </tr>
                </tbody>
            </table>
            <h2>See Also</h2>
            <ul>
                <li><a href="dbconsole_features.html">User Interface Features of the Splice&#160;Machine Database Console</a>
                </li>
                <li><a href="dbconsole_queries.html">Managing Queries with the Console</a>
                </li>
                <li><a href="developers_fundamentals_sparklibs.html">Using Spark Libraries with Splice Machine</a>
                </li>
            </ul>
        </div>
	</section>
