<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="How to use our Bulk HFile import feature to rapidly import large datasets into your Splice Machine database.">
<meta name="keywords" content=" bulk import, bulk data load, hfile import, hfile load, s3, aws">
<title>Importing Data into Your Splice Machine Database | Splice Machine Documentation</title>
<link rel="stylesheet" href="css/syntax.css">


<link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
<link rel="stylesheet" href="css/modern-business.css">
<link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
<!--<link rel="stylesheet" href="css/lavish-bootstrap.css"> -->
<!--<link rel="stylesheet" href="css/customstyles.css"> -->
<link rel="stylesheet" href="css/splicemain.css">

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.4/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="js/jquery.navgoco.min.js"></script>


<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/2.0.0/anchor.min.js"></script>
<script src="js/toc.js"></script>
<script src="js/customscripts.js"></script>

<link rel="shortcut icon" href="images/favicon.ico">

<!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
<![endif]-->

<link rel="alternate" type="application/rss+xml" title="" href="http://localhost:4000/feed.xml">

    <script>
        $(document).ready(function() {
            // Initialize navgoco with default options
            $("#mysidebar").navgoco({
                caretHtml: '',
                accordion: true,
                openClass: 'active', // open
                save: false, // leave false or nav highlighting doesn't work right
                cookie: {
                    name: 'navgoco',
                    expires: false,
                    path: '/'
                },
                slide: {
                    duration: 400,
                    easing: 'swing'
                }
            });

            $("#collapseAll").click(function(e) {
                e.preventDefault();
                $("#mysidebar").navgoco('toggle', false);
            });

            $("#expandAll").click(function(e) {
                e.preventDefault();
                $("#mysidebar").navgoco('toggle', true);
            });

        });

    </script>
    <script>
        $(function () {
            $('[data-toggle="tooltip"]').tooltip()
        })
    </script>
    <script>
        $(document).ready(function() {
            $("#tg-sb-link").click(function() {
                $("#tg-sb-sidebar").toggle();
                $("#tg-sb-content").toggleClass('col-md-9');
                $("#tg-sb-content").toggleClass('col-md-12');
                $("#tg-sb-icon").toggleClass('fa-toggle-on');
                $("#tg-sb-icon").toggleClass('fa-toggle-off');
            });
        });
    </script>
    

</head>
<body>
<!-- Navigation -->
<nav class="navbar navbar-inverse navbar-static-top">
    <div class="container-fluid topnavlinks">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="fa fa-home fa-lg navbar-brand" href="index.html">&nbsp;<span class="projectTitle"> Splice Machine Documentation</span></a>
        </div>
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <!-- toggle sidebar button -->
                <li><a id="tg-sb-link" href="#"><i id="tg-sb-icon" class="fa fa-toggle-on"></i> Nav</a></li>
                <!-- entries without drop-downs appear here -->
                
                
                
                <!-- entries with drop-downs appear here -->
                <!-- conditional logic to control which topnav appears for the audience defined in the configuration file.-->
                
                
                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Splice Machine<b class="caret"></b></a>
                    <ul class="dropdown-menu">
                        
                        
                        <li><a href="index.html">Welcome</a></li>
                        
                        
                        
                        <li><a href="tutorials_intro.html">Tutorials</a></li>
                        
                        
                        
                        <li><a href="sqlref_intro.html">SQL Reference Manual</a></li>
                        
                        
                        
                        <li><a href="developers_intro.html">Developer's Manual</a></li>
                        
                        
                        
                        <li><a href="dbconsole_intro.html">Database Console</a></li>
                        
                        
                        
                        <li><a href="notes_intro.html">General Information</a></li>
                        
                        
                    </ul>
                </li>
                
                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">DB-Service Only<b class="caret"></b></a>
                    <ul class="dropdown-menu">
                        
                        
                        <li><a href="dbaas_intro.html">Welcome!</a></li>
                        
                        
                        
                        <li><a href="dbaas_cm_intro.html">Cloud Manager Guide</a></li>
                        
                        
                        
                        <li><a href="dbaas_zep_intro.html">Using Zeppelin</a></li>
                        
                        
                        
                        <li><a href="dbaas_info_intro.html">Release Information</a></li>
                        
                        
                    </ul>
                </li>
                
                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">On-Premise-DB Only<b class="caret"></b></a>
                    <ul class="dropdown-menu">
                        
                        
                        <li><a href="onprem_intro.html">Welcome!</a></li>
                        
                        
                        
                        <li><a href="onprem_install_intro.html">Installation</a></li>
                        
                        
                        
                        <li><a href="cmdlineref_intro.html">splice> Command Line Reference</a></li>
                        
                        
                        
                        <li><a href="onprem_admin_intro.html">Administrator's Guide</a></li>
                        
                        
                        
                        <li><a href="onprem_info_intro.html">Release Information</a></li>
                        
                        
                    </ul>
                </li>
                
                
                
                <!--comment out this block if you want to hide search-->
                <li>
                    <!--start search-->
                    <div id="search-demo-container">
                        <input type="text" id="search-input" placeholder="search...">
                        <ul id="results-container"></ul>
                    </div>
                    <script src="js/jekyll-search.js" type="text/javascript"></script>
                    <script type="text/javascript">
                            SimpleJekyllSearch.init({
                                searchInput: document.getElementById('search-input'),
                                resultsContainer: document.getElementById('results-container'),
                                dataSource: 'search.json',
                                searchResultTemplate: '<li><a href="{url}" title="Importing Data into Your Splice Machine Database">{title}</a></li>',
                    noResultsText: 'No results found.',
                            limit: 10,
                            fuzzy: true,
                    })
                    </script>
                    <!--end search-->
                </li>
            </ul>
        </div>
        </div>
        <!-- /.container -->
</nav>

<!-- Page Content -->
<div class="container-fluid">
    <!-- Content Row -->
    <div class="row">
        
        
            <!-- Sidebar Column -->
            <div class="col-md-3" id="tg-sb-sidebar">
                

<ul id="mysidebar" class="nav">
    <li class="sidebarTitle">Splice Machine 2.6</li>
    
    
    
    <li>
        <a href="#">Splice Machine Tutorials</a>
        <ul>
            
            
            
            <li><a href="tutorials_intro.html">Introduction</a></li>
            
            
            
            
        </ul>
     </li>
       
        
    
    <li>
        <a href="#">splice> Command Line</a>
        <ul>
            
            
            
            <li><a href="tutorials_cli_usingcli.html">Getting Started With splice></a></li>
            
            
            
            
            
            
            <li><a href="tutorials_cli_scripting.html">Scripting splice></a></li>
            
            
            
            
            
            
            <li><a href="tutorials_cli_rlwrap.html">RlWrap Summary</a></li>
            
            
            
            
        </ul>
     </li>
       
        
    
    <li>
        <a href="#">Ingestion and Streaming</a>
        <ul>
            
            
            
            <li><a href="tutorials_ingest_uploadtos3.html">Uploading Data to S3</a></li>
            
            
            
            
            
            
            <li><a href="tutorials_ingest_configures3.html">Setting up S3 Access</a></li>
            
            
            
            
            
            
            <li><a href="tutorials_ingest_tpch1.html">Importing TPCH Data</a></li>
            
            
            
            
            
            
            <li><a href="tutorials_ingest_importing.html">Importing Your Data</a></li>
            
            
            
            
            
            
            <li class="active"><a href="tutorials_ingest_hfiles.html">Importing Your Data as HFiles</a></li>
            
            
            
            
            
            
            <li><a href="tutorials_ingest_kafkaproducer.html">Creating a Kafka Producer</a></li>
            
            
            
            
            
            
            <li><a href="tutorials_ingest_kafkafeed.html">Configuring a Kafka Feed</a></li>
            
            
            
            
            
            
            <li><a href="tutorials_ingest_storm.html">Using Apache Storm</a></li>
            
            
            
            
            
            
            <li><a href="tutorials_ingest_mqttspark.html">MQTT&#160;Spark Streaming</a></li>
            
            
            
            
        </ul>
     </li>
       
        
    
    <li>
        <a href="#">Analytics and Machine Learning</a>
        <ul>
            
            
            
            <li><a href="tutorials_ml_zeppelin.html">Using Zeppelin</a></li>
            
            
            
            
        </ul>
     </li>
       
        
    
    <li>
        <a href="#">Connecting Programmatically</a>
        <ul>
            
            
            
            <li><a href="tutorials_connect_haproxy.html">Connecting through HAProxy</a></li>
            
            
            
            
            
            
            <li><a href="tutorials_connect_java.html">Connecting with Java</a></li>
            
            
            
            
            
            
            <li><a href="tutorials_connect_jruby.html">Connecting with JRuby</a></li>
            
            
            
            
            
            
            <li><a href="tutorials_connect_jython.html">Connecting with Jython</a></li>
            
            
            
            
            
            
            <li><a href="tutorials_connect_scala.html">Connecting with Scala</a></li>
            
            
            
            
            
            
            <li><a href="tutorials_connect_angular.html">Connecting with NodeJS</a></li>
            
            
            
            
            
            
            <li><a href="tutorials_connect_odbcinstall.html">Installing our ODBC&#160;Driver</a></li>
            
            
            
            
            
            
            <li><a href="tutorials_connect_python.html">Connecting with Python</a></li>
            
            
            
            
            
            
            <li><a href="tutorials_connect_odbcc.html">Connecting with C&#160;and ODBC</a></li>
            
            
            
            
        </ul>
     </li>
       
        
    
    <li>
        <a href="#">Connecting BI Tools</a>
        <ul>
            
            
            
            <li><a href="tutorials_connect_dbeaver.html">Connecting DBeaver</a></li>
            
            
            
            
            
            
            <li><a href="tutorials_connect_dbvisualizer.html">Connecting DBVisualizer</a></li>
            
            
            
            
            
            
            <li><a href="tutorials_connect_cognos.html">Connecting Cognos</a></li>
            
            
            
            
            
            
            <li><a href="tutorials_connect_squirrel.html">Connecting SQuirreL</a></li>
            
            
            
            
            
            
            <li><a href="tutorials_connect_tableau.html">Connecting Tableau</a></li>
            
            
            
            
        </ul>
     </li>
       
        
        
        <!-- if you aren't using the accordion, uncomment this block:
           <p class="external">
               <a href="#" id="collapseAll">Collapse All</a> | <a href="#" id="expandAll">Expand All</a>
           </p>
           -->
</ul>

<!-- this highlights the active parent class in the navgoco sidebar. this is critical so that the parent expands when you're viewing a page. This must appear below the sidebar code above. Otherwise, if placed inside customscripts.js, the script runs before the sidebar code runs and the class never gets inserted.-->
<script>$("li.active").parents('li').toggleClass("active");</script>

            </div>
            
        

        <!-- Content Column -->
        <div class="col-md-9" id="tg-sb-content">
            

<div class="post-content">

<!--- Don't automatically put page summary at top - GRH 05/2017:
   
    <div class="summary">How to use our Bulk HFile import feature to rapidly import large datasets into your Splice Machine database.</div>
   
-->

    


    

  	<section>
		<div class="TopicContent">
            <h1 id="kanchor104">Importing Data in HFile Format Into Splice Machine</h1>
            <p>This tutorial describes how to import data using HFiles into your Splice Machine database, and includes a number of examples. It also contains specific tips to help you with the details of getting your data correctly imported. This tutorial contains these sections:</p>
            <ul>
                <li><span class="ItalicFont">How&#160;Importing Your Data as HFiles Works</span> presents an overview of using the HFile import functions.</li>
                <li> <span class="ItalicFont">Usage Notes</span> provides an overview of the steps you use to import your data as HFiles.</li>
                <li><span class="ItalicFont">Examples</span> contains two example of importing data in HFile format.</li>
                <li><a href="#Tips">Tips for Importing Data into Splice&#160;Machine</a> provides specific tips for specifying your import parameters.</li>
            </ul>
            <p>If you're importing data from an S3 bucket on AWS, please review our <a href="tutorials_ingest_configures3.html">Configuring an S3 Bucket for Splice Machine Access</a> tutorial before proceeding.</p>
            <div class="noteIcon">Our <a href="tutorials_ingest_importing.html">Importing Your Data tutorial</a> walks you through using our standard import procedure, which is easier to use, though slightly slower than importing HFiles.</div>
            <h2 id="How">How Importing Your Data as HFiles Works</h2>
            <p>Our HFile data import procedure leverages HBase bulk loading, which allows it to import your data at a faster rate; however, using this procedure instead of our standard <span class="CodeFont"><a href="tutorials_ingest_importing.html">SYSCS_UTIL.IMPORT_DATA</a></span>&#160;procedure means that <span class="ItalicFont">constraint checks are not performing during data importation</span>.</p>
            <p>You import a table as HFiles using our <span class="CodeFont">SYSCS_UTIL.BULK_IMPORT_HFILES</span> procedure, which temporarily converts the table file that you're importing into HFiles, imports those directly into your database, and then removes the temporary HFiles. Before it generate HFiles, <span class="CodeFont">SYSCS_UTIL.BULK_IMPORT_HFILES</span> must determine how to split the data into multiple regions by looking at the primary keys and figuring out which values will yield relatively evenly-sized splits; the objective is to compute splits such that roughly the same number of table rows will end up in each split.</p>
            <p><span class="CodeFont">SYSCS_UTIL.BULK_IMPORT_HFILES</span> can scan and analyze your table to determine the best splits; or you can exercise control over those splits.</p>
            <p>To have <span class="CodeFont">SYSCS_UTIL.BULK_IMPORT_HFILES</span> calculate the splits automatically, simply call this procedure with the <span class="CodeFont">skipSampling</span> parameter set to <span class="CodeFont">true</span>.</p>
            <p>If you want to control the splits yourself, use these steps, which are detailed in the <span class="ItalicFont">Examples</span> section below:</p>
            <ul>
                <li>You must determine which values make sense for splitting your data into multiple regions. This means looking at the primary keys for the table and figuring out which values will yield relatively evenly-sized splits, which means that roughly the same number of table rows will end up in each split. </li>
                <li>Calling one of our system procedures to compute the HBase-encoded keys to create those splits.</li>
                <li>Calling one of our system procedures to set up the splits inside your&#160;Splice&#160;Machine database.</li>
                <li>Call our <span class="CodeFont">SYSCS_UTIL.BULK_IMPORT_HFILES</span> procedure, which temporarily converts the table file that you're importing into HFiles, imports those directly into your database, and then removes the temporary HFiles.</li>
            </ul>
﻿        <p class="heading2"><a name="Usage"></a>Usage Notes</p>
        <p class="body">As mentioned earlier, you can have <span class="CodeFont">SYSCS_UTIL.BULK_IMPORT_HFILE</span> automatically compute the splits for your table; it does so by sampling the data in the table, generating a histogram, and then using that histogram to compute the import splits. <span class="CodeFont">SYSCS_UTIL.BULK_IMPORT_HFILE</span> automatically computes the splits when the <span class="CodeFont">skipSampling</span> parameter is set to <span class="CodeFont">false</span>.</p>
        <p class="heading3">Computing Split Keys for HFile Import</p>
        <div class="noteIcon">If you are using <span class="CodeFont">skipSampling=false</span> to allow automatic computation of splits, you can ignore the rest of this section, and skip to the <a href="#Examples">Examples</a> section below.</div>
        <p>If you're computing splits for your import (and setting the <span class="CodeFont">skipSampling</span> parameter to <span class="CodeFont">true</span>), you need to use these three Splice&#160;Machine system procedures together:</p>
        <ul>
            <li><span class="CodeFont">SYSCS_UTIL.COMPUTE_SPLIT_KEY</span> generates a keys file</li>
            <li><span class="CodeFont">SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX_AT_POINTS</span> sets up the splits in Splice&#160;Machine</li>
            <li><span class="CodeFont">SYSCS_UTIL.BULK_IMPORT_HFILE</span>&#160;splits your input file into HFiles, imports your data, and then removes the HFiles</li>
        </ul>
        <p>Alternatively, you can use  <span class="CodeFont"><a href="sqlref_sysprocs_splittable.html">SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX</a></span> with <span class="CodeFont">SYSCS_UTIL.BULK_IMPORT_HFILE</span>. The <span class="CodeFont">SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX</span> system procedure combines the functionality of <span class="CodeFont">SYSCS_UTIL.COMPUTE_SPLIT_KEY</span> and <span class="CodeFont">SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX_AT_POINTS</span>.</p>
        <p>The process is as follows (and is shown in more detail in <span class="ItalicFont">Example 1</span> and <span class="ItalicFont">Example 2</span> below):</p>
        <div class="opsStepsList">
            <ol>
                <li>
                    <p>Create a directory on HDFS; for example:</p>
                    <div class="preWrapperWide"><pre class="ShellCommand">sudo -su hdfs hadoop fs -mkdir hdfs:///tmp/test_hfile_import</pre>
                    </div>
                    <p>Make sure that the directory you create has permissions set to allow Splice&#160;Machine to write your csv and Hfiles there.</p>
                </li>
                <li>
                    <p>Determine primary key values that can horizontally split the table into roughly equal sized partitions. </p>
                    <div class="noteNote">
                        <p>Note the value of your <span class="CodeFont">hbase.hregion.max.filesize</span> setting; each partition should ideally be about 1/2 of that value, so that the region can grow after data is loaded. </p>
                        <p>The sizes must be less than the <span class="CodeFont">hbase.hregion.max.filesize value</span>.</p>
                    </div>
                </li>
                <li>Store those keys in a CSV&#160;file.</li>
                <li> If you're using the combination of <span class="CodeFont"><a href="sqlref_sysprocs_computesplitkey.html">SYSCS_UTIL.COMPUTE_SPLIT_KEY</a></span> and <span class="CodeFont"><a href="sqlref_sysprocs_splittableatpoints.html">SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX_AT_POINTS</a></span>:<ol class="LowerAlphaPlainFont"><li>Pass that CSV&#160;file into the <span class="CodeFont"><a href="sqlref_sysprocs_computesplitkey.html">SYSCS_UTIL.COMPUTE_SPLIT_KEY</a></span>&#160;procedure to compute the split row keys.</li><li><p>Examine the computed (and encoded)&#160;row keys, which were written to a file named keys in a subdirectory of your <span class="CodeFont">OutputDirectory</span>. </p><p>The name of the subdirectory is the conglomerate ID&#160;for the named table. You can find a table's conglomerate ID&#160;with the <span class="CodeFont"><a href="cmdlineref_cmdshowtables.html">SHOW&#160;TABLES</a></span>&#160;command.&#160;</p></li><li>Copy the encoded keys to your clipboard.</li><li>Call the <span class="CodeFont"><a href="sqlref_sysprocs_splittableatpoints.html">SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX_AT_POINTS</a></span>&#160;procedure, passing in the row key values from your clipboard. This splits your table inside the database.</li></ol><p>If you are using  the single procedure <span class="CodeFont"><a href="sqlref_sysprocs_splittable.html">SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX</a></span> instead:</p><ol class="LowerAlphaPlainFont"><li>Pass that CSV&#160;file into the <span class="CodeFont"><a href=".sqlref_sysprocs_splittable.html">SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX</a></span>&#160;procedure to compute the split row keys and split your table inside the database.</li></ol></li>
                <li>Repeat steps 1, 2, and 3 to split the indexes on your table.</li>
                <li>Call the <span class="CodeFont"><a href="sqlref_sysprocs_importhfile.html">SYSCS_UTIL.BULK_IMPORT_HFILE</a></span>&#160;procedure to split the input data file into HFiles and import the HFiles into your Splice Machine database. The HFiles are deleted after being imported.</li>
            </ol>
        </div>
        <p class="heading2" id="Examples"></a>Example 1</p>
        <p>This example details the steps used to import data in HFile format using the Splice Machine <span class="CodeFont">SYSCS_UTIL.BULK_IMPORT_HFILE</span> system procedure with automatic splitting.</p>
        <p>Follow these steps :</p>
        <div class="opsStepsList">
            <ol class="boldFont">
                <li>
                    <p class="topLevel">Create a directory on HDFS for the import; for example:</p>
                    <div class="preWrapperWide"><pre class="ShellCommand">sudo -su hdfs hadoop fs -mkdir hdfs:///tmp/test_hfile_import</pre>
                    </div>
                    <p>Make sure that the directory you create has permissions set to allow Splice&#160;Machine to write your csv and Hfiles there.</p>
                </li>
                <li>
                    <p class="topLevel">Create table and index:</p>
                    <div class="preWrapperWide"><pre class="Example">CREATE TABLE TPCH.LINEITEM (
		 L_ORDERKEY BIGINT NOT NULL,
		 L_PARTKEY INTEGER NOT NULL,
		 L_SUPPKEY INTEGER NOT NULL,
		 L_LINENUMBER INTEGER NOT NULL,
		 L_QUANTITY DECIMAL(15,2),
		 L_EXTENDEDPRICE DECIMAL(15,2),
		 L_DISCOUNT DECIMAL(15,2),
		 L_TAX DECIMAL(15,2),
		 L_RETURNFLAG VARCHAR(1),
		 L_LINESTATUS VARCHAR(1),
		 L_SHIPDATE DATE,
		 L_COMMITDATE DATE,
		 L_RECEIPTDATE DATE,
		 L_SHIPINSTRUCT VARCHAR(25),
		 L_SHIPMODE VARCHAR(10),
		 L_COMMENT VARCHAR(44),
		 PRIMARY KEY(L_ORDERKEY,L_LINENUMBER)
		 );

CREATE&#160;INDEX&#160;L_SHIPDATE_IDX on TPCH.LINEITEM(
		 L_SHIPDATE,
		 L_PARTKEY,
		 L_EXTENDEDPRICE,
		 L_DISCOUNT
		 );</pre>
                    </div>
                </li>
                <li>
                    <p class="topLevel">Import the HFiles Into Your Database</p>
                    <p class="indentLevel1">Once you have split your table and indexes, call this procedure to generate and import the HFiles into your Splice Machine database:</p>
                    <div class="preWrapperWide"><pre class="Example">call SYSCS_UTIL.BULK_IMPORT_HFILE('TPCH', 'LINEITEM', null, '/TPCH/1/lineitem', '|', null, null, null, null, -1, '/BAD', true, null, 'hdfs:///tmp/test_hfile_import/', false);</pre>
                    </div>
                    <p class="indentLevel1">The generated HFiles are automatically deleted after being imported.</p>
                </li>
            </ol>
        </div>
        <p class="heading2">Example 2</>
        <p>The example in this section details the steps used to import data in HFile format using the Splice Machine <span class="CodeFont">SYSCS_UTIL.COMPUTE_SPLIT_KEY</span>,  <span class="CodeFont">SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX_AT_POINTS</span>, and <span class="CodeFont">SYSCS_UTIL.BULK_IMPORT_HFILE</span> system procedures.</p>
        <p>Follow these steps :</p>
        <div class="opsStepsList">
            <ol class="boldFont">
                <li>
                    <p class="topLevel">Create a directory on HDFS for the import; for example:</p>
                    <div class="preWrapperWide"><pre class="ShellCommand">sudo -su hdfs hadoop fs -mkdir hdfs:///tmp/test_hfile_import</pre>
                    </div>
                    <p>Make sure that the directory you create has permissions set to allow Splice&#160;Machine to write your csv and Hfiles there.</p>
                </li>
                <li>
                    <p class="topLevel">Create table and index:</p>
                    <div class="preWrapperWide"><pre class="Example">CREATE TABLE TPCH.LINEITEM (
		 L_ORDERKEY BIGINT NOT NULL,
		 L_PARTKEY INTEGER NOT NULL,
		 L_SUPPKEY INTEGER NOT NULL,
		 L_LINENUMBER INTEGER NOT NULL,
		 L_QUANTITY DECIMAL(15,2),
		 L_EXTENDEDPRICE DECIMAL(15,2),
		 L_DISCOUNT DECIMAL(15,2),
		 L_TAX DECIMAL(15,2),
		 L_RETURNFLAG VARCHAR(1),
		 L_LINESTATUS VARCHAR(1),
		 L_SHIPDATE DATE,
		 L_COMMITDATE DATE,
		 L_RECEIPTDATE DATE,
		 L_SHIPINSTRUCT VARCHAR(25),
		 L_SHIPMODE VARCHAR(10),
		 L_COMMENT VARCHAR(44),
		 PRIMARY KEY(L_ORDERKEY,L_LINENUMBER)
		 );

CREATE&#160;INDEX&#160;L_SHIPDATE_IDX on TPCH.LINEITEM(
		 L_SHIPDATE,
		 L_PARTKEY,
		 L_EXTENDEDPRICE,
		 L_DISCOUNT
		 );</pre>
                    </div>
                </li>
                <li>
                    <p class="topLevel">Compute the split row keys for the table:</p>
                    <ol class="LowerAlphaPlainFont">
                        <li>
                            <p>Find primary key values that can horizontally split the table into roughly equal sized partitions.</p>
                            <p>For this example, we provide 3 keys in a file named <span class="CodeFont">lineitemKey.csv</span>. Note that each of our three keys includes a second column that is <span class="CodeFont">null</span>:</p>
                            <div class="preWrapperWide"><pre class="Example">1500000|<br />3000000|<br />4500000|</pre>
                            </div>
                        </li>
                        <li>
                            <p>Specify the column names in the csv file in the <span class="CodeFont">columnList</span> parameter; in our example, the primary key columns are:</p>
                            <div class="preWrapperWide"><pre class="Example">'L_ORDERKEY,L_LINENUMBER'</pre>
                            </div>
                        </li>
                        <li>
                            <p>Invoke <span class="CodeFont">SYSCS_UTIL.COMPUTE_SPLIT_KEY</span> to compute hbase split row keys and write them to a file:</p><pre class="Example">call SYSCS_UTIL.COMPUTE_SPLIT_KEY('TPCH', 'LINEITEM',null, 'L_ORDERKEY,L_LINENUMBER', 'hdfs:///tmp/test_hfile_import/lineitemKey.csv', '|', null, null, null, null, -1, '/BAD', true, null, 'hdfs:///tmp/test_hfile_import/');</pre>
                        </li>
                    </ol>
                </li>
                <li>
                    <p class="topLevel">Set up the table splits in your database:</p>
                    <ol class="LowerAlphaPlainFont">
                        <li>
                            <p>Use <span class="CodeFont">SHOW&#160;TABLES</span>&#160;to discover the conglomerate ID&#160;for the <span class="CodeFont">TPCH.LINEITEM</span>&#160;table, which for this example is <span class="CodeFont">1536</span>. This means that the split keys file for this table is in the <span class="CodeFont">hdfs:///tmp/test_hfile_import/1536</span> directory. You'll see values like these:</p>
                            <div class="preWrapperWide"><pre class="Example">\xE4\x16\xE3`<br />\xE4-\xC6\xC0<br />\xE4D\xAA</pre>
                            </div>
                        </li>
                        <li>
                            <p>Now use those values in a call to our system procedure to split the table inside the database:</p>
                            <div class="preWrapperWide"><pre class="Example">call SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX_AT_POINTS('TPCH','LINEITEM',null,'\xE4\x16\xE3`,\xE4-\xC6\xC0,\xE4D\xAA');</pre>
                            </div>
                        </li>
                    </ol>
                </li>
                <li>
                    <p class="topLevel">Compute the split keys for your index:</p>
                    <ol class="LowerAlphaPlainFont">
                        <li>Find index values that can horizontally split the table into roughly equal sized partitions.</li>
                        <li>
                            <p>For this example, we provide 2 index values in a file named <span class="CodeFont">shipDateIndex.csv</span>. Note that each of our keys includes <span class="CodeFont">null</span> column values:</p>
                            <div class="preWrapperWide"><pre class="Example">1994-01-01|||
1996-01-01|||</pre>
                            </div>
                        </li>
                        <li>
                            <p>Specify the column names in the csv file in the <span class="CodeFont">columnList</span> parameter; in our example, the index columns are:</p>
                            <div class="preWrapperWide"><pre class="Example">'L_SHIPDATE,L_PARTKEY,L_EXTENDEDPRICE,L_DISCOUNT'</pre>
                            </div>
                        </li>
                        <li>
                            <p>Invoke <span class="CodeFont">SYSCS_UTIL.COMPUTE_SPLIT_KEY</span> to compute hbase split row keys and write them to a file:</p><pre class="Example">call SYSCS_UTIL.COMPUTE_SPLIT_KEY('TPCH', 'LINEITEM', 'L_SHIPDATE_IDX', 'L_SHIPDATE,L_PARTKEY,L_EXTENDEDPRICE,L_DISCOUNT', 'hdfs:///tmp/test_hfile_import/shipDateIndex.csv', '|', null, null, null, null, -1, '/BAD', true, null, 'hdfs:///tmp/test_hfile_import/');
</pre>
                        </li>
                    </ol>
                </li>
                <li>
                    <p class="topLevel">Set up the indexes in your database:</p>
                    <ol class="LowerAlphaPlainFont">
                        <li>
                            <p>Copy the row key values from the output file:</p>
                            <div class="preWrapperWide"><pre class="Example">\xEC\xB0Y9\xBC\x00\x00\x00\x00\x00\x80
\xEC\xBF\x08\x9C\x14\x00\x00\x00\x00\x00\x80</pre>
                            </div>
                        </li>
                        <li>
                            <p>Now call our system procedure to split the index:</p>
                            <div class="preWrapperWide"><pre class="Example">call SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX_AT_POINTS('TPCH','LINEITEM','L_SHIPDATE_IDX','\xEC\xB0Y9\xBC\x00\x00\x00\x00\x00\x80,\xEC\xBF\x08\x9C\x14\x00\x00\x00\x00\x00\x80');
</pre>
                            </div>
                        </li>
                    </ol>
                </li>
                <li>
                    <p class="topLevel">Import the HFiles Into Your Database</p>
                    <p class="indentLevel1">Once you have split your table and indexes, call this procedure to generate and import the HFiles into your Splice Machine database:</p>
                    <div class="preWrapperWide"><pre class="Example">call SYSCS_UTIL.BULK_IMPORT_HFILE('TPCH', 'LINEITEM', null, '/TPCH/1/lineitem', '|', null, null, null, null, -1, '/BAD', true, null, 'hdfs:///tmp/test_hfile_import/', true);</pre>
                    </div>
                    <p class="indentLevel1">The generated HFiles are automatically deleted after being imported.</p>
                </li>
            </ol>
        </div>
        <p class="heading2">Example 3</p>
        <p>The example in this section details the steps used to import data in HFile format using the Splice Machine  <span class="CodeFont">SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX</span>, and <span class="CodeFont">SYSCS_UTIL.BULK_IMPORT_HFILE</span> system procedures.</p>
        <p>Follow these steps :</p>
        <div class="opsStepsList">
            <ol class="boldFont">
                <li>
                    <p class="topLevel">Create a directory on HDFS for the import; for example:</p>
                    <div class="preWrapperWide"><pre class="ShellCommand">sudo -su hdfs hadoop fs -mkdir hdfs:///tmp/test_hfile_import</pre>
                    </div>
                    <p>Make sure that the directory you create has permissions set to allow Splice&#160;Machine to write your csv and Hfiles there.</p>
                </li>
                <li>
                    <p class="topLevel">Create table and index:</p>
                    <div class="preWrapperWide"><pre class="Example">CREATE TABLE TPCH.LINEITEM (
		 L_ORDERKEY BIGINT NOT NULL,
		 L_PARTKEY INTEGER NOT NULL,
		 L_SUPPKEY INTEGER NOT NULL,
		 L_LINENUMBER INTEGER NOT NULL,
		 L_QUANTITY DECIMAL(15,2),
		 L_EXTENDEDPRICE DECIMAL(15,2),
		 L_DISCOUNT DECIMAL(15,2),
		 L_TAX DECIMAL(15,2),
		 L_RETURNFLAG VARCHAR(1),
		 L_LINESTATUS VARCHAR(1),
		 L_SHIPDATE DATE,
		 L_COMMITDATE DATE,
		 L_RECEIPTDATE DATE,
		 L_SHIPINSTRUCT VARCHAR(25),
		 L_SHIPMODE VARCHAR(10),
		 L_COMMENT VARCHAR(44),
		 PRIMARY KEY(L_ORDERKEY,L_LINENUMBER)
		 );

CREATE&#160;INDEX&#160;L_SHIPDATE_IDX on TPCH.LINEITEM(
		 L_SHIPDATE,
		 L_PARTKEY,
		 L_EXTENDEDPRICE,
		 L_DISCOUNT
		 );</pre>
                    </div>
                </li>
                <li>
                    <p class="topLevel">Compute the split row keys for your table and set up the split in your database:</p>
                    <ol class="LowerAlphaPlainFont">
                        <li>
                            <p>Find primary key values that can horizontally split the table into roughly equal sized partitions.</p>
                            <p>For this example, we provide 3 keys in a file named <span class="CodeFont">lineitemKey.csv</span>. Note that each of our three keys includes a second column that is <span class="CodeFont">null</span>:</p>
                            <div class="preWrapperWide"><pre class="Example">1500000|<br></br>3000000|<br></br>4500000|</pre>
                            </div>
                        </li>
                        <li>
                            <p>Specify the column names in the csv file in the <span class="CodeFont">columnList</span> parameter; in our example, the primary key columns are:</p>
                            <div class="preWrapperWide"><pre class="Example">'L_ORDERKEY,L_LINENUMBER'</pre>
                            </div>
                        </li>
                        <li>
                            <p>Invoke <span class="CodeFont">SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX</span> to compute hbase split row keys and set up the splits</p><pre class="Example">call SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX('TPCH', 'LINEITEM',null, 'L_ORDERKEY,L_LINENUMBER', 'hdfs:///tmp/test_hfile_import/lineitemKey.csv', '|', null, null, null, null, -1, '/BAD', true, null);</pre>
                        </li>
                    </ol>
                </li>
                <li>
                    <p class="topLevel">Compute the split keys for your index:</p>
                    <ol class="LowerAlphaPlainFont">
                        <li>Find index values that can horizontally split the table into roughly equal sized partitions.</li>
                        <li>
                            <p>For this example, we provide 2 index values in a file named <span class="CodeFont">shipDateIndex.csv</span>. Note that each of our keys includes <span class="CodeFont">null</span> column values:</p>
                            <div class="preWrapperWide"><pre class="Example">1994-01-01|||
1996-01-01|||</pre>
                            </div>
                        </li>
                        <li>
                            <p>Specify the column names in the csv file in the <span class="CodeFont">columnList</span> parameter; in our example, the index columns are:</p>
                            <div class="preWrapperWide"><pre class="Example">'L_SHIPDATE,L_PARTKEY,L_EXTENDEDPRICE,L_DISCOUNT'</pre>
                            </div>
                        </li>
                        <li>
                            <p>Invoke <span class="CodeFont">SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX</span> to compute hbase split row keys and set up the index splits</p><pre class="Example">call SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX('TPCH', 'LINEITEM', 'L_SHIPDATE_IDX', 'L_SHIPDATE,L_PARTKEY,L_EXTENDEDPRICE,L_DISCOUNT', 'hdfs:///tmp/test_hfile_import/shipDateIndex.csv', '|', null, null, null, null, -1, '/BAD', true, null);
</pre>
                        </li>
                    </ol>
                </li>
                <li>
                    <p class="topLevel">Import the HFiles Into Your Database</p>
                    <p class="indentLevel1">Once you have split your table and indexes, call this procedure to generate and import the HFiles into your Splice Machine database:</p>
                    <div class="preWrapperWide"><pre class="Example">call SYSCS_UTIL.BULK_IMPORT_HFILE('TPCH', 'LINEITEM', null, '/TPCH/1/lineitem', '|', null, null, null, null, -1, '/BAD', true, null, 'hdfs:///tmp/test_hfile_import/', true);</pre>
                    </div>
                    <p class="indentLevel1">The generated HFiles are automatically deleted after being imported.</p>
                </li>
            </ol>
        </div>

            <h2 id="Tips">Tips for Importing Data into Splice&#160;Machine</h2>
            <p>This tutorial contains a number of tips that our users have found very useful in determining the parameter settings to use when running an import:</p>
            <ol>
                <li><a href="#Tip4"><a href="#Tip4">Tip #1:&#160;&#160;Use Special Characters for Delimiters</a></a>
                </li>
                <li><a href="#Tip5"><a href="#Tip5">Tip #2:&#160;&#160;Avoid Problems With Date, Time, and Timestamp Formats</a></a>
                </li>
                <li><a href="#Tip6"><a href="#Tip6">Tip #3:&#160;&#160;Change the Bad Directory for Each Table / Group</a></a>
                </li>
                <li><a href="#Tip7"><a href="#Tip7">Tip #4:&#160;&#160;Importing Multi-line Records</a></a>
                </li>
                <li><a href="#Tip8"><a href="#Tip8">Tip #5:&#160;&#160;Importing CLOBs and BLOBs</a></a>
                </li>
                <li><a href="#Tip9">Tip #6:&#160;&#160;Scripting Your Imports</a>
                </li>
            </ol>
            <h3 id="Tip4">Tip #1:&#160;&#160;Use Special Characters for Delimiters</h3>
            <p>One common gotcha we see with customer imports is when the data you're importing includes a special character that you've designated as a column or character delimiter. You'll end up with records in your bad record directory and can spend hours trying to determine the issue, only to discover that it's because the data includes a delimiter character. This can happen with columns that contain data such as product descriptions. </p>
            <h4>Column Delimiters</h4>
            <p>The  standard column delimiter is a comma (<span class="CodeFont">,</span>); however, we've all worked with string data that contains commas, and have figured out to use a different column delimiter. Some customers use the pipe (<span class="CodeFont">|</span>)&#160;character, but frequently discover that it is also used in some descriptive data in the table they're importing. </p>
            <p>We recommend using a control character like <span class="CodeFont">CTRL-A</span> for your column delimiter. This is known as the SOH&#160;character, and is represented by 0x01 in hexadecimal. Unfortunately, there's no way to enter this character from the keyboard in the Splice&#160;Machine command line interface; instead, you need to create a script file (see <a href="#Tip9">Tip #9</a>) and type the control character using a text editor like <span class="ItalicFont">vi</span> or <span class="ItalicFont">vim</span>:</p>
            <ul>
                <li>Open your script file in vi or vim.</li>
                <li>Enter into INSERT&#160;mode.</li>
                <li>Type <span class="CodeFont">CTRL-V</span> then <span class="CodeFont">CTRL-A</span> for the value of the column delimiter parameter in your procedure call. Note that this typically echoes as <span class="CodeFont">^A</span> when you type it in vi or vim.</li>
            </ul>
            <h4>Character Delimiters</h4>
            <p>By default, the character delimiter is a double quote. This can produce the same kind of problems that we see with using a comma for the column delimiter:&#160;columns values that include embedded quotes or use the double quote as the symbol for inches. You can use escape characters to include the embedded quotes, but it's easier to use a special character for your delimiter. </p>
            <p>We recommend using <span class="CodeFont">CTRL-G</span>, which you can add to a script file (see <a href="#Tip9">Tip #9</a>), again using a text editor like <span class="ItalicFont">vi</span> or <span class="ItalicFont">vim</span>:</p>
            <ul>
                <li>Open your script file in vi or vim.</li>
                <li>Enter into INSERT&#160;mode.</li>
                <li>Type <span class="CodeFont">CTRL-V</span> then <span class="CodeFont">CTRL-G</span> for the value of the character delimiter parameter in your procedure call. Note that this typically echoes as <span class="CodeFont">^G</span> when you type it in vi or vim.</li>
            </ul>
            <h3 id="Tip5">Tip #2:&#160;&#160;Avoid Problems With Date, Time, and Timestamp Formats</h3>
            <p>Perhaps the most common difficulty that customers have with importing their data is with date, time, and timestamp values. </p>
            <p>Splice Machine adheres to the Java <span class="CodeFont">SimpleDateFormat</span> syntax for all date, time, and timestamp values, <span class="CodeFont">SimpleDateFormat</span> is described here:</p>
            <p class="indentLevel1"><a href="https://docs.oracle.com/javase/8/docs/api/java/text/SimpleDateFormat.html"  target="_blank">https://docs.oracle.com/javase/8/docs/api/java/text/SimpleDateFormat.html</a>
            </p>
            <p>Splice Machine's implementation of <span class="CodeFont">SimpleDateFormat</span> is case-sensitive; this means, for example, that a lowercase <span class="CodeFont">h</span> is used to represent an hour value between 0 and 12, whereas an uppercase <span class="CodeFont">H</span> is used to represent an hour between 0 and 23.</p>
            <p>Splice Machine's Import procedures only allow you to specify one format each for the date, time, and timestamp columns in the table data you are importing. This means that, for example, every date in the table data must be in the same format.</p>
            <div class="notePlain">
                <p>All of the <span class="CodeFont">Date</span> values in the file (or group of files) you are importing must use the same date format.</p>
                <p>All of the <span class="CodeFont">Time</span> values in the file (or group of files) you are importing must use the same time format.</p>
                <p>All of the <span class="CodeFont">Timestamp</span> values in the file (or group of files) you are importing must use the same timestamp format.</p>
            </div>
            <p>A few additional notes:</p>
            <ul>
                <li>The <span class="CodeFont">Timestamp</span> data type has a range of <span class="CodeFont">1678-01-01</span> to <span class="CodeFont">2261-12-31</span>. Some customers have used dummy timestamp values like <span class="CodeFont">9999-01-01</span>, which will fail because the value is out of range for a timestamp. Note that this is not an issue with <span class="CodeFont">Date</span> values.</li>
                <li>Splice Machine suggests that, if your data contains any date or timestamp values that are not in the format <span class="CodeFont">yyyy-MM-dd HH:mm:ss</span>, you create a simple table that has just one or two columns and test importing the format. This is a simple way to confirm that the imported data is what you expect.</li>
            </ul>
            <h3 id="Tip6">Tip #3:&#160;&#160;Change the Bad Directory for Each Table / Group</h3>
            <p>If you are importing a large amount of data and have divided the files you are importing into groups, then it's a good idea to change the location of the bad record directory for each group; this will make debugging bad records a lot easier for you.</p>
            <p>You can change the value of the <span class="CodeFont">badRecordDirectory</span> to include your group name; for example, we typically use a strategy like the following:</p>
            <table style="width: 100%;">
                <col />
                <col />
                <thead>
                    <tr>
                        <th>Group Files Location</th>
                        <th><span class="CodeBoldFont">badRecordDirectory</span> Parameter Value</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td class="CodeFont">/data/mytable1/group1</td>
                        <td class="CodeFont">/BAD/mytable1/group1</td>
                    </tr>
                    <tr>
                        <td class="CodeFont">/data/mytable1/group2</td>
                        <td class="CodeFont">/BAD/mytable1/group2</td>
                    </tr>
                    <tr>
                        <td class="CodeFont">/data/mytable1/group3</td>
                        <td class="CodeFont">/BAD/mytable1/group3</td>
                    </tr>
                </tbody>
            </table>
            <p>You'll then be able to more easily discover where the problem record is located.</p>
            <h3 id="Tip7">Tip #4:&#160;&#160;Importing Multi-line Records</h3>
            <p>If your data contains line feed characters like <span class="CodeFont">CTRL-M</span>, you need to set the <span class="CodeFont">oneLineRecords</span> parameter to <span class="CodeFont">false</span>. Splice Machine will accommodate to the line feeds; however, the import will take longer because Splice&#160;Machine will not be able to break the file up and distribute it across the cluster.</p>
            <div class="notePlain">
                <p>To improve import performance, avoid including line feed characters in your data and set the <span class="CodeFont">oneLineRecords</span> parameter to <span class="CodeFont">true</span>. </p>
            </div>
            <h3 id="Tip8">Tip #5:&#160;&#160;Importing CLOBs and BLOBs</h3>
            <p>If you are importing <span class="CodeFont">CLOB</span>s, pay careful attention to tips <a href="#Tip4">4</a> and <a href="#Tip7">7</a>. Be sure to use special characters for both your column and character delimiters. If your <span class="CodeFont">CLOB</span> data can span multiple lines, be sure to set the <span class="CodeFont">oneLineRecords</span> parameter to <span class="CodeFont">false</span>. </p>
            <p>At this time, the Splice Machine import procedures do not import work with columns of type <span class="CodeFont">BLOB</span>. You can create a virtual table interface (VTI)&#160;that reads the <span class="CodeFont">BLOB</span>s and inserts them into your database.</p>
            <h3 id="Tip9">Tip #6:&#160;&#160;Scripting Your Imports</h3>
            <p>You can make import tasks much easier and convenient by creating <span class="ItalicFont">import scripts</span>. An import script is simply a call to one of the import procedures; once you've verified that it works, you can use and clone the script and run unattended imports.</p>
            <p>An import script is simply a file in which you store <span class="CodeFont">splice&gt;</span>&#160;commands that you can execute with the <span class="CodeFont">run</span> command. For example, here's an example of a text file named <span class="CodeFont">myimports.sql</span> that we can use to import two csv files into our database:</p>
            <div class="preWrapperWide"><pre class="Example">call SYSCS_UTIL.IMPORT_DATA ('SPLICE','mytable1',null,'/data/mytable1/data.csv',null,null,null,null,null,0,'/BAD/mytable1',null,null);<br />call SYSCS_UTIL.IMPORT_DATA ('SPLICE','mytable2',null,'/data/mytable2/data.csv',null,null,null,null,null,0,'/BAD/mytable2',null,null</pre>
            </div>
            <p>To run an import script, use the <span class="CodeFont">splice&gt;&#160;run</span> command; for example:</p>
            <div class="preWrapper"><pre class="Example">splice&gt;&#160;run 'myimports.sql';</pre>
            </div>
            <p>You can also start up the <span class="CodeFont">splice&gt;</span>&#160;command line interpreter with the name of a file to run; for example:</p>
            <div class="preWrapper"><pre class="Example">sqlshell.sh -f myimports.sql</pre>
            </div>
            <p>In fact, you can script almost any sequence of Splice Machine commands in a file and run that script within the command line interpreter or when you start the interpreter.</p>
        </div>
	</section>


    <div class="tags">
        
    </div>



</div>

<hr class="shaded"/>

<footer>
            <div class="row">
                <div class="col-lg-12 footer">
               &copy;2017 Splice Machine, Inc. All rights reserved. <br />
 Site last generated: Jul 20, 2017 <br />
<p><img src="images/company_logo.png" alt="Company logo"/></p>
                </div>
            </div>
</footer>


        </div>
    <!-- /.row -->
</div>
<!-- /.container -->
    </div>

</body>

<!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-35630173-2','auto');ga('require','displayfeatures');ga('send','pageview');</script>


</html>
