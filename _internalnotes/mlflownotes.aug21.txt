MLFlow
    - puts tags in your code
    - assumes tags are on same machine as tracking GUI

PySpark

Begin with raw data
    Iterate to figure out feature vectors
        Iterate over different algorithms
            Each algorithm has different parameters


Workflow: Teams of data scientists can manage and annotate model runs


Sagemaker: allows you to build models and scale deployment of models
    --> leverage it for scale-out on AWS
    (can deploy at arbitrary scale)

i.e. we coexist with AWS/Sagemaker
   (will do same thing with Azure)

not reinventing the wheel -- you can still use AWS/Azure's ML environment
